{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwavEDpGfPsrw8W4VC9igU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoMinetti/Colab/blob/main/DeepLearning_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7kePYFqK8SW"
      },
      "source": [
        "# Deep Learning com Keras\r\n",
        "Esse Notebook foi criado visando Estudar a Biblioteca Keras do Google para treinar modelos de Deep Learning utilizando rede neural sequêncial com otimizador Back Propagation.\r\n",
        "\r\n",
        "Modelo desenvolvido durante a aula do Samsung Ocean com o Professor Paulo Salvatore.\r\n",
        "\r\n",
        "Aula Deep Learning: Introdução com Keras e Python, partes 1 e 2.\r\n",
        "\r\n",
        "Aluno: Bruno Cesar Minetti Sanches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkOXAfYNST5O"
      },
      "source": [
        "## Bibliotecas utilizadas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tSCYZKvKwwL"
      },
      "source": [
        "### Bibliotecas:\r\n",
        "# Importa a biblioteca Keras:\r\n",
        "import keras\r\n",
        "# Base de Dados MNIST:\r\n",
        "from keras.datasets import mnist \r\n",
        "# Arquitetura da nossa rede neural:\r\n",
        "from tensorflow.python.keras import Sequential \r\n",
        "# Neurônio (base da rede) e Regularizador (evita overfitting):\r\n",
        "from tensorflow.python.keras.layers import Dense, Dropout \r\n",
        "# Otimizador (back propagation):\r\n",
        "from tensorflow.compat.v1.keras.optimizers import RMSprop\r\n",
        "# Plota modelos gráficos:\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "# Traz Funções matemáticas simplificadas:\r\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR8jhd0dSXpU"
      },
      "source": [
        "## Carregando o Dataset Mnist do Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw6-e-pYMjoU",
        "outputId": "d39437fe-689d-49da-faf1-be879b7e90bc"
      },
      "source": [
        "'''\r\n",
        "Carregando os dados de treino e teste, o Keras já traz em sua biblioteca\r\n",
        "um banco de imagens para treinar o modelo, sem ter a necessidade de buscar,\r\n",
        "ou mesmo ter que criar esse banco, o que é bastante complicado, e parte \r\n",
        "importante para a criação de um bom modelo de machine learning.\r\n",
        "'''\r\n",
        "\r\n",
        "(x_treino, y_treino), (x_teste, y_teste) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skcmzjGXNNR3",
        "outputId": "c3918bc9-f085-43c7-a021-800f8ab71293"
      },
      "source": [
        "'''\r\n",
        "Após importar os dados, é importante analisar o dataset e veridicar o que temos \r\n",
        "e como ele está estruturado.\r\n",
        "'''\r\n",
        "\r\n",
        "print(\"Quantidade de imagens para treino:\", len(x_treino))\r\n",
        "print(\"Quantidade de imagens para teste:\", len(x_teste))\r\n",
        "print(\"Tipo de x_treino:\", type(x_treino))\r\n",
        "\r\n",
        "primeira_imagem = x_treino[0]\r\n",
        "representacao_primeira_imagem = y_treino[0]\r\n",
        "\r\n",
        "print(\"O que a imagem 0 representa:\", representacao_primeira_imagem)\r\n",
        "print(\"Formato da primeira imagem:\", primeira_imagem.shape,\r\n",
        "      type(primeira_imagem.shape))\r\n",
        "print(primeira_imagem)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de imagens para treino: 60000\n",
            "Quantidade de imagens para teste: 10000\n",
            "Tipo de x_treino: <class 'numpy.ndarray'>\n",
            "O que a imagem 0 representa: 5\n",
            "Formato da primeira imagem: (28, 28) <class 'tuple'>\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "LJlQxLVrOQhS",
        "outputId": "f9041e2e-3385-44ac-966a-37fe98a8db46"
      },
      "source": [
        "# Visualizando como a imagem é utilizando MatPlotLib:\r\n",
        "\r\n",
        "indice = 12000\r\n",
        "print(\"A imagem representa:\", y_treino[indice])\r\n",
        "plt.imshow(x_treino[indice], cmap=plt.cm.binary)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A imagem representa: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1611288c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zVtLRKJO_57"
      },
      "source": [
        " ## Fluxo para construção de rede neural\r\n",
        "- Organizar a camada de entrada (input)\r\n",
        "- Organizar a camada de saída (output)\r\n",
        "- Estruturar a nossa rede neural\r\n",
        "- Treinar o modelo\r\n",
        "- Fazer as previsões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtodWvwSOtm"
      },
      "source": [
        "## Achatando o Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNA_TStAPKlX"
      },
      "source": [
        "'''\r\n",
        "Achatando a matriz de pixels e transformando em uma única lista.\r\n",
        "Procure evitar criar muitas variáveis duplicadas, isso além de deixar seu\r\n",
        "notebook pesado, pode provocar confusão, \"nomear suas variáveis com sabedoria,\r\n",
        "você deve, pequeno padauan.\"\r\n",
        "'''\r\n",
        "\r\n",
        "quantidade_treino = len(x_treino) # 60000\r\n",
        "quantidade_teste = len(x_teste) # 10000\r\n",
        "\r\n",
        "resolucao_imagem = x_treino[0].shape # (28, 28)\r\n",
        "resolucao_total = resolucao_imagem[0] * resolucao_imagem[1] # 28 * 28 = 784\r\n",
        "\r\n",
        "x_treino = x_treino.reshape(quantidade_treino, resolucao_total)\r\n",
        "x_teste = x_teste.reshape(quantidade_teste, resolucao_total)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTfUrfAaPwVe",
        "outputId": "b3e60bd5-9063-4cdd-a74a-3e3eda4ab8c1"
      },
      "source": [
        "# Verificando como seu dataset ficou após o achatamento\r\n",
        "\r\n",
        "print(\"Quantidade de itens em x_treino[0]:\", len(x_treino[0]))\r\n",
        "\r\n",
        "# Como ficou x_treino[0]?\r\n",
        "print(x_treino[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de itens em x_treino[0]: 784\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG8SwO-BSKHd"
      },
      "source": [
        "## Normalizando os Dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKw7t4KSQWC7"
      },
      "source": [
        "'''\r\n",
        "Normalização dos dados\r\n",
        "\r\n",
        "A ideia é manter os valores do modelo entre zero e um então, o \"255\" vira 1,\r\n",
        "\"127\" vira 0.5, 0 se mantém, mudando a escala.\r\n",
        "\r\n",
        "Converte toda a base de x_treino de uint_8 para float32, isso é necessário para\r\n",
        "atender a critérios da biblioteca. Podemos verificar isso na documentação\r\n",
        "técnica do Keras.\r\n",
        "'''\r\n",
        "x_treino = x_treino.astype('float32') \r\n",
        "x_teste = x_teste.astype('float32') \r\n",
        "\r\n",
        "'''\r\n",
        "Dividimos todos os 60000 valores de x_treino por 255 e armazenamos os resultados\r\n",
        "em x_treino novamente, evitando criar novas variáveis inúteis.\r\n",
        "'''\r\n",
        "x_treino /= 255\r\n",
        "'''\r\n",
        "E fazemos o mesmo com x_teste dividindo todos os 10000 valores de x_teste por\r\n",
        "255 e armazenamos os resultados em x_teste novamente.\r\n",
        "'''\r\n",
        "x_teste /= 255 "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EnLNnRsSFhJ",
        "outputId": "f141676c-edfc-44f2-f855-7b7e2e65c9ea"
      },
      "source": [
        "'''\r\n",
        "Acessamos a primeira imagem, disponível em x_treino[0], e depois exibimos qual o\r\n",
        "valor está no pixel 350 da imagem.\r\n",
        "Lembrando que cada linha possui 28 pixels (0-27), portanto ao acessar o índice \r\n",
        "28, estamos acessando o 1º pixel da segunda linha.\r\n",
        "'''\r\n",
        "\r\n",
        "print('valor está em x_treino[0] no pixel 350 da imagem:', x_treino[0][350],\r\n",
        "      type(x_treino[0][350]))\r\n",
        "print(x_treino[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valor está em x_treino[0] no pixel 350 da imagem: 0.27450982 <class 'numpy.float32'>\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6GhN-RzTUDx"
      },
      "source": [
        "## Preparando a camada de saída do modelo:\r\n",
        "\r\n",
        "Preparação da camada de saída (output):\r\n",
        "\r\n",
        "- Quais são as possibilidades de saída? Números de 0 a 9\r\n",
        "- Quantos itens temos? 10 itens\r\n",
        "- Números  -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n",
        "- Número 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "- Número 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "- Número 9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB_KJKS9TR8w",
        "outputId": "fc8cf2ff-0705-4052-ac17-24931bcc381f"
      },
      "source": [
        "valores_unicos = set(y_treino) # {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\r\n",
        "print(valores_unicos)\r\n",
        "\r\n",
        "quantidade_valores_unicos = len(valores_unicos) # 10\r\n",
        "print(quantidade_valores_unicos)\r\n",
        "\r\n",
        "print(\"y_treino[0] antes:\", y_treino[0])\r\n",
        "\r\n",
        "y_treino = keras.utils.to_categorical(y_treino, quantidade_valores_unicos)\r\n",
        "y_teste = keras.utils.to_categorical(y_teste, quantidade_valores_unicos)\r\n",
        "\r\n",
        "print(\"y_treino[0] depois:\", y_treino[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10\n",
            "y_treino[0] antes: 5\n",
            "y_treino[0] depois: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmjiRHKYTyo4"
      },
      "source": [
        "## Criando o modelo de rede neural sequêncial:\r\n",
        "\r\n",
        "Primeira hidden layer:\r\n",
        "-  30 neurônios;\r\n",
        "- Função de ativação: ReLU;\r\n",
        "- Como estamos na primeira hidden layer, precisamos informar o formato da camada de entrada (input), lembrando que esse precisa estar em formato de tupla.\r\n",
        "\r\n",
        "Adicionamos um regularizador (bias) nessa primeira camada, que ajuda a evitar o overfitting. No caso, será o Dropout.\r\n",
        "\r\n",
        "Segunda hidden layer:\r\n",
        "- 20 neurônios\r\n",
        "- Função de ativação: ReLU\r\n",
        "\r\n",
        "Adicionamos um regularizador para segunda hidden layer.\r\n",
        "\r\n",
        "Finalizamos com a camada de saída (output), informando a quantidade de valores únicos que, no caso, é 10, de 0 a 9.\r\n",
        "\r\n",
        "Função de ativação: Como ReLU deve usada apenas nas hidden layers, pois não performa bem nessa camada de ativação, iremos utilizar a função Softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ4pFnTET5Hq",
        "outputId": "2e33c669-762a-4ae1-dd16-ae7d20b68324"
      },
      "source": [
        "model = Sequential() # Criando o modelo da rede neural\r\n",
        "\r\n",
        "\r\n",
        "#Primeira hidden layer:\r\n",
        "model.add(Dense(30, activation='relu', input_shape=(resolucao_total,)))\r\n",
        "\r\n",
        "#Adicionando um regularidor (bias) na primeira camada:\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# Segunda hidden layer:\r\n",
        "model.add(Dense(20, activation='relu'))\r\n",
        "\r\n",
        "# Adicionando o regularizador para a segunda camada:\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "#Adicionando a última camada:\r\n",
        "model.add(Dense(quantidade_valores_unicos, activation='softmax'))\r\n",
        "\r\n",
        "# Exibe o resumo do modelo criado\r\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 24,380\n",
            "Trainable params: 24,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfusayeyYzv5"
      },
      "source": [
        "## Compilando e treinando o modelo:\r\n",
        "Precisamos informar qual será:\r\n",
        "- A função de erro;\r\n",
        "- O algoritmo de backpropagation, importado junto com as bibliotecas;\r\n",
        "- Os Dados para Treino (imagens normalizadas e labels categorizadas);\r\n",
        "- Os Dados para Teste (imagens normalizadas e labels categorizadas);\r\n",
        "- A quantidade de épocas que queremos rodar (sendo 1 época equivalente a analisar TODAS as imagens de treino);\r\n",
        "- O Tamanho de cada 'batch':\r\n",
        "> Supondo que temos 100 imagens, pode ser muito pesado para processar de uma única vez, portanto, quebramos em 'batches' de 10 imagens, cada, e processamos 10 imagens por vez, geralmente, o tamanho dos batches deve ser potência de 2 (2, 4, 8, 16, 32, 64, 128, ...), para melhorar performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HWDiJZAaB_q",
        "outputId": "cf785584-b88d-478c-8160-5f27d56cfe86"
      },
      "source": [
        "# Compilamos o modelo:\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=RMSprop(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# Treinamos o modelo (verbose serve para vizualizar o treinamento):\r\n",
        "\r\n",
        "history = model.fit(x_treino, y_treino,\r\n",
        "                    batch_size=128,\r\n",
        "                    epochs=10,\r\n",
        "                    verbose=1,\r\n",
        "                    validation_data=(x_teste, y_teste))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.2531 - accuracy: 0.5870 - val_loss: 0.3122 - val_accuracy: 0.9128\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.8418 - val_loss: 0.2525 - val_accuracy: 0.9256\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8737 - val_loss: 0.2212 - val_accuracy: 0.9352\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8897 - val_loss: 0.2024 - val_accuracy: 0.9403\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8966 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.9034 - val_loss: 0.1808 - val_accuracy: 0.9480\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.9084 - val_loss: 0.1776 - val_accuracy: 0.9484\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.9144 - val_loss: 0.1684 - val_accuracy: 0.9529\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.9151 - val_loss: 0.1691 - val_accuracy: 0.9519\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9165 - val_loss: 0.1654 - val_accuracy: 0.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TozoqLMcaYl6"
      },
      "source": [
        "## Lendo imagens de teste:\r\n",
        "\r\n",
        "Como o model.predict aceita mais de uma imagem ao mesmo tempo e queremos apenas analisar uma imagem, precisamos fazer um reshape, em que [0, 0, 0, 0], vira [[0, 0, 0, 0]]\r\n",
        "\r\n",
        "Fazemos a previsão da imagem, porém o retorno é de uma série, que fica difícil de ler, contudo o valor mais provável da imagem será o mais alto, ou o que se aproxima mais de 1, lembrando que os valores estão normalizados.\r\n",
        "\r\n",
        "Transformamos então a previsão em algo que conseguimos entender de forma mais fácil, utilizando o Numpy. Convertemos a previsão que está em porcentagens, pegando o maior valor disponível da lista.\r\n",
        "\r\n",
        "Recarregamos o MNIST e exibimos a imagem original usando o matplotlib carregado anteriormente para comparar se o número foi lido corretamente pelo modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "0KMsPuwHb3XO",
        "outputId": "0ed9ecf8-89ca-4855-a604-7ca56c94d3c7"
      },
      "source": [
        "'''\r\n",
        "O índice serve para alterarmos a imagem de teste que queremos ler com o modelo.\r\n",
        "'''\r\n",
        "indice = 7503\r\n",
        "\r\n",
        "print(\"Valor categórico em y_teste[indice]:\", y_teste[indice])\r\n",
        "\r\n",
        "# Reshape da imagem:\r\n",
        "imagem = x_teste[indice].reshape((1, resolucao_total))\r\n",
        "\r\n",
        "# Fazemos a previsão da imagem:\r\n",
        "prediction = model.predict(imagem)\r\n",
        "print(\"Previsão:\", prediction)\r\n",
        "\r\n",
        "# Transformando a previsão em algo mais fácil de entender:\r\n",
        "prediction_class = np.argmax(prediction, axis=-1)\r\n",
        "print(\"Previsão ajustada:\", prediction_class)\r\n",
        "\r\n",
        "'''\r\n",
        "Recarregamos o MNIST e exibimos a imagem original usando o matplotlib carregado \r\n",
        "anteriormente, lembrando que durante :\r\n",
        "'''\r\n",
        "(x_treino_img, y_treino_img), (x_teste_img, y_teste_img) = mnist.load_data()\r\n",
        "plt.imshow(x_teste_img[indice], cmap=plt.cm.binary);"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor categórico em y_teste[indice]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "Previsão: [[1.68704182e-01 5.26821781e-11 1.20880827e-03 2.04211597e-06\n",
            "  8.93023480e-06 3.48912142e-02 7.93975174e-01 1.98096051e-09\n",
            "  1.19932985e-03 1.03737075e-05]]\n",
            "Previsão ajustada: [6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}